{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, dense_dim, output_dim, num_layers, use_gpu, batch_size, is_training=True, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ;input_dim: 30\n",
    "            ;hidden_dim: 60\n",
    "            ;dense_dim: 512\n",
    "            ;output_dim: 4\n",
    "            ;num_layers: 2 #stack two bilstm layers\n",
    "        \"\"\"\n",
    "        super(BiLSTM, self).__init__()\n",
    "        # inti self values\n",
    "        self.use_gpu = use_gpu\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "        self.is_training = is_training\n",
    "\n",
    "        # define layers\n",
    "        self.bilstm = nn.LSTM(input_size=input_dim, num_layers=num_layers, hidden_size=hidden_dim, bidirectional=True)\n",
    "        self.dense_hidden = nn.Linear(hidden_dim*2, dense_dim)\n",
    "        self.dense_out = nn.Linear(dense_dim, output_dim)\n",
    "\n",
    "        # define hidden, cell for BiLSTM\n",
    "        ## (num_layers * num_directions, batch, hidden_size)\n",
    "        if use_gpu:\n",
    "            self.h_0 = Variable(torch.zeros(2 * num_layers, self.batch_size, hidden_dim).cuda())\n",
    "            self.c_0 = Variable(torch.zeros(2 * num_layers, self.batch_size, hidden_dim).cuda())\n",
    "        else:\n",
    "            self.h_0 = Variable(torch.zeros(2 * num_layers, self.batch_size, hidden_dim))\n",
    "            self.c_0 = Variable(torch.zeros(2 * num_layers, self.batch_size, hidden_dim))\n",
    "\n",
    "    def forward(self, audio_features):\n",
    "        # audio_features = (seq_len, batch, input_size)\n",
    "#         lstm_output, (h_1, c_1) = self.bilstm(audio_features, (self.h_0, self.c_0))\n",
    "        lstm_output, (h_1, c_1) = self.bilstm(audio_features)\n",
    "        \n",
    "        #(seq_len, batch, input_size)  => (batch, input_size), only last output\n",
    "        hidden_1 = self.dense_hidden(lstm_output[-1])  \n",
    "        y = self.dense_out(hidden_1)\n",
    "\n",
    "        # for cross entropy loss\n",
    "        if self.is_training:\n",
    "            return y\n",
    "        else:\n",
    "            return F.softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM hyperparams\n",
    "input_dim = 30\n",
    "hidden_dim = 60\n",
    "dense_dim = 512\n",
    "output_dim = 4\n",
    "num_layers = 2\n",
    "use_gpu = True\n",
    "is_cuda = True\n",
    "is_training=True\n",
    "batch_size = 32\n",
    "dropout=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = BiLSTM(\n",
    "    input_dim,\n",
    "    hidden_dim,\n",
    "    dense_dim,\n",
    "    output_dim,\n",
    "    num_layers,\n",
    "    use_gpu,\n",
    "    batch_size,\n",
    "    is_training,\n",
    "    dropout\n",
    ")\n",
    "\n",
    "if is_cuda:\n",
    "    bilstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(bilstm.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "data_dir = \"../data/feature_array/\"\n",
    "features_dir = data_dir + \"audio_features.npy\"\n",
    "labels_dir = data_dir + \"labels.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ang': 0, 'exc': 1, 'neu': 2, 'sad': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "labels = np.load(labels_dir)\n",
    "features = np.load(features_dir)\n",
    "# features = np.moveaxis(features, 0, -2).transpose()\n",
    "\n",
    "# label string to onehot\n",
    "label_map_dict = {lab:i for i, lab in enumerate(np.unique(labels))}\n",
    "I_matrix = np.eye(len(label_map_dict))\n",
    "labels_onehot = np.array([I_matrix[label_map_dict[lab]] for lab in labels])\n",
    "labels_int = np.array([label_map_dict[lab] for lab in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split: 대략 10%\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features, labels_int, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, train_features, train_labels): \n",
    "        self.len = len(train_labels)\n",
    "        self.X = torch.from_numpy(train_features).float().to(device)\n",
    "        self.y = torch.from_numpy(train_labels).long().to(device)\n",
    "        \n",
    "    def __getitem__(self, index): \n",
    "        return self.X[index], self.y[index] \n",
    "    \n",
    "    def __len__(self): \n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate batch\n",
    "dataset = AudioDataset(train_features, train_labels)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training process\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, answers = data\n",
    "        # (batch, input_size, seq_len) => (seq_len, batch, input_size)\n",
    "        inputs_permute = inputs.permute(2,0,1) \n",
    "        \n",
    "        outputs = bilstm(inputs_permute)\n",
    "        \n",
    "        loss = criterion(outputs, answers)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data.item()\n",
    "        \n",
    "        losses.append(loss)\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm.is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9158036920306168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/irteam/anaconda3/envs/py36_torch/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# train predict\n",
    "sample_train = torch.tensor(train_features).float().permute(2,0,1).to(device)\n",
    "predict_train = bilstm(sample_train).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "print(\"train accuracy:\", sum(predict_train == train_labels) / len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.4817813765182186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/irteam/anaconda3/envs/py36_torch/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# test predict\n",
    "sample_test = torch.tensor(test_features).float().permute(2,0,1).to(device)\n",
    "predict_test = bilstm(sample_test).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "print(\"test accuracy:\", sum(predict_test == test_labels) / len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f53be0b7940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "(pd.Series(labels).value_counts()/len(labels)).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save as state_dict\n",
    "- https://tutorials.pytorch.kr/beginner/saving_loading_models.html#state-dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bilstm.state_dict(), \"../data/bilstm_state_dict.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_torch]",
   "language": "python",
   "name": "conda-env-py36_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
